{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Prediction from the RetinaNet\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Intersections-over-Union\n",
    "\n",
    "Categorize the Predictions in 'true positives', 'false positives' and 'false negatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(r1,r2):\n",
    "    '''\n",
    "    Overlapping rectangles overlap both horizontally & vertically\n",
    "    '''\n",
    "    \n",
    "    #print(r1)\n",
    "    #print(r2)\n",
    "    \n",
    "    r1_left   = r1[0]\n",
    "    r1_right  = r1[2]\n",
    "    r1_bottom = r1[3]\n",
    "    r1_top    = r1[1]\n",
    "    \n",
    "    r2_left   = r2[0]\n",
    "    r2_right  = r2[2]\n",
    "    r2_bottom = r2[3]\n",
    "    r2_top    = r2[1]\n",
    "    \n",
    "    overlaps = False\n",
    "    \n",
    "    dx = min(r1[2], r2[2]) - max(r1[0], r2[0])\n",
    "    dy = min(r1[3], r2[3]) - max(r1[1], r2[1])\n",
    "    \n",
    "    if (dx >= 0) and (dy >= 0):\n",
    "        overlaps = True\n",
    "        \n",
    "    return overlaps\n",
    "\n",
    "def intersects_with_gt(detected, gt, iou_thres, idx):\n",
    "    \n",
    "    #print(idx)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    if len(gt) is 0:\n",
    "        print('No Ground-Truth boxes')\n",
    "        return\n",
    "    \n",
    "    #print('Detected:', len(detected))\n",
    "    #print('Ground-Truth:', len(gt))\n",
    "    \n",
    "    for i, detected_box in enumerate(detected):        \n",
    "        for gt_box in gt:\n",
    "            \n",
    "            #print('Detected:', detected_box)\n",
    "            #print('Ground-Truth:', gt_box)\n",
    "            if overlap(detected_box, gt_box):\n",
    "                \n",
    "                a = detected_box\n",
    "                b = gt_box\n",
    "                                \n",
    "                # COORDINATES OF THE INTERSECTION BOX\n",
    "                x1 = max(a[0], b[0])\n",
    "                y1 = max(a[1], b[1])\n",
    "                x2 = min(a[2], b[2])\n",
    "                y2 = min(a[3], b[3])\n",
    "\n",
    "                # AREA OF OVERLAP - Area where the boxes intersect\n",
    "                width = (x2 - x1)\n",
    "                height = (y2 - y1)\n",
    "        \n",
    "                area_overlap = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "                # COMBINED AREA\n",
    "                area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "                area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "                area_combined = area_a + area_b - area_overlap\n",
    "                \n",
    "                #print('Area a: ', area_a)\n",
    "                #print('Area b: ', area_b)\n",
    "                #print('Area combined: ', area_combined)\n",
    "                #print('Area overlap: ', area_overlap)\n",
    "\n",
    "                # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "                #iou = area_overlap / (area_combined+epsilon)\n",
    "                iou = area_overlap / area_combined\n",
    "                #iou = area_overlap / area_combined\n",
    "                \n",
    "                #print('iou: ', iou, \" num: \", (id_num + i))\n",
    "                \n",
    "                #print('IOU: ', iou)\n",
    "                \n",
    "                if(iou >= iou_thres):\n",
    "                    tp += 1\n",
    "     \n",
    "    fn = len(gt) - tp\n",
    "    if fn < 0: \n",
    "        fn = 0\n",
    "        \n",
    "    fp = len(detected) - tp\n",
    "    \n",
    "    result = {}\n",
    "    result['tp'] = tp\n",
    "    result['fp'] = fp\n",
    "    result['fn'] = fn\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ground-truth data for the mating-events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filepath):\n",
    "    \n",
    "    result_data = dict()\n",
    "    \n",
    "    with open(filepath) as json_file:\n",
    "        train_dataset = json.load(json_file)\n",
    "        \n",
    "    ann = train_dataset['annotations']\n",
    "    #print(ann)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for a in ann:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        if a['category_id'] is 1:\n",
    "            \n",
    "            #print(a)\n",
    "            \n",
    "            idx = a['image_id']\n",
    "            tmp_box = [float(x) for x in a['bbox']]\n",
    "            \n",
    "            x2 = tmp_box[0] + tmp_box[2]\n",
    "            y2 = tmp_box[1] + tmp_box[3]\n",
    "            \n",
    "            bbox = [tmp_box[0], tmp_box[1], x2, y2]\n",
    "        \n",
    "            if idx in result_data:\n",
    "            \n",
    "                result_data[idx].append(bbox)\n",
    "            else:\n",
    "                \n",
    "                tmp = []\n",
    "                tmp.append(bbox)\n",
    "                result_data[idx] = tmp\n",
    "    \n",
    "    #print('Iterated through: ', counter, \" images.\")\n",
    "    print('done')\n",
    "    return result_data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out the mating-events from the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matings(pred_dataset):\n",
    "\n",
    "    pred_data = dict()\n",
    "\n",
    "    for d in pred_dataset:\n",
    "    \n",
    "        idx = d['image_id']\n",
    "        bbox = [float(x) for x in d['bbox']]\n",
    "        \n",
    "        if d['category_id'] is 1:\n",
    "    \n",
    "            if idx in pred_data:\n",
    "        \n",
    "                pred_data[idx].append(bbox)        \n",
    "            else:\n",
    "        \n",
    "                tmp = []\n",
    "        \n",
    "                tmp.append(bbox)\n",
    "        \n",
    "                pred_data[idx] = tmp\n",
    "\n",
    "    print(len(pred_data), ' done')\n",
    "    \n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data for the Train and Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/scratch/ganswindt/retinanet/COCO/DIR/'\n",
    "ANNOTATION_DIR = os.path.join(ROOT_DIR, \"annotations\")\n",
    "\n",
    "results_filepath = '/scratch/ganswindt/retinanet/'\n",
    "val = os.path.join(results_filepath, 'result_1906-val-2.json')\n",
    "train = os.path.join(results_filepath, 'result_1906-train-2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  done\n",
      "71  done\n"
     ]
    }
   ],
   "source": [
    "with open(val) as json_file:\n",
    "    dataset_val = json.load(json_file)\n",
    "\n",
    "pred_data_val = get_matings(dataset_val)\n",
    "\n",
    "with open(train) as json_file:\n",
    "    dataset_train = json.load(json_file)\n",
    "\n",
    "pred_data_train = get_matings(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ground-truth data for the Train and Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "8\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "val_file = ANNOTATION_DIR + '/instances_val.json'\n",
    "train_file = ANNOTATION_DIR + '/instances_train.json'\n",
    "    \n",
    "gt_boxes_val = read_json(val_file)\n",
    "gt_boxes_train = read_json(train_file)\n",
    "\n",
    "#print(gt_boxes_val[70])\n",
    "print(len(gt_boxes_val))\n",
    "print(len(gt_boxes_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize the Predictions for the Validation dataset in TP, FP and FN\n",
    "\n",
    "(TP: true positives, fp: false positives, fn: false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Ground-Truth Boxes in Val:  64\n",
      "Num predicted Boxes for Val:  61\n"
     ]
    }
   ],
   "source": [
    "results_val = dict()\n",
    "\n",
    "results_val['tp'] = 0\n",
    "results_val['fp'] = 0\n",
    "results_val['fn'] = 0\n",
    "\n",
    "counter = 0\n",
    "counter_pred = 0\n",
    "\n",
    "for d in pred_data_val:\n",
    "    for g in gt_boxes_val:\n",
    "        \n",
    "        if d is g:\n",
    "               \n",
    "            boxes = pred_data_val[d]\n",
    "            gt = gt_boxes_val[g]\n",
    "            \n",
    "            counter += len(gt)\n",
    "            counter_pred += len(boxes)\n",
    "            \n",
    "            tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "            \n",
    "            results_val['tp'] = results_val['tp'] + tmp['tp']\n",
    "            results_val['fp'] = results_val['fp'] + tmp['fp']\n",
    "            results_val['fn'] = results_val['fn'] + tmp['fn']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print('Num Ground-Truth Boxes in Val: ', counter)\n",
    "print('Num predicted Boxes for Val: ', counter_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy for the Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'tp': 50, 'fp': 11, 'fn': 17}\n",
      "81.9672131147541 %\n"
     ]
    }
   ],
   "source": [
    "print('Results: ', results_val)\n",
    "\n",
    "#1306: 19.49 %\n",
    "print(results_val['tp']/(results_val['tp'] + results_val['fp']) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize the Predictions for the Train dataset in TP, FP and FN\n",
    "\n",
    "(TP: true positives, fp: false positives, fn: false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Ground-Truth Boxes in Train:  629\n",
      "Num predicted Boxes for Val:  610\n"
     ]
    }
   ],
   "source": [
    "results_train = dict()\n",
    "\n",
    "results_train['tp'] = 0\n",
    "results_train['fp'] = 0\n",
    "results_train['fn'] = 0\n",
    "\n",
    "counter = 0\n",
    "counter_pred = 0\n",
    "\n",
    "for d in pred_data_train:\n",
    "    for g in gt_boxes_train:\n",
    "        \n",
    "        if d is g:\n",
    "               \n",
    "            boxes = pred_data_train[d]\n",
    "            gt = gt_boxes_train[g]\n",
    "            \n",
    "            counter += len(gt)\n",
    "            counter_pred += len(boxes)\n",
    "            \n",
    "            tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "            \n",
    "            results_train['tp'] = results_train['tp'] + tmp['tp']\n",
    "            results_train['fp'] = results_train['fp'] + tmp['fp']\n",
    "            results_train['fn'] = results_train['fn'] + tmp['fn']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print('Num Ground-Truth Boxes in Train: ', counter)\n",
    "print('Num predicted Boxes for Val: ', counter_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy for the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'tp': 591, 'fp': 19, 'fn': 102}\n",
      "96.88524590163935 %\n"
     ]
    }
   ],
   "source": [
    "print('Results:', results_train)\n",
    "\n",
    "#1306: 85.26 %\n",
    "print(results_train['tp']/(results_train['tp'] + results_train['fp']) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Val:  21.875\n",
      "Error Train:  6.041335453100159\n"
     ]
    }
   ],
   "source": [
    "error_val = ((get_items(gt_boxes_val) - results_val['tp']) / get_items(gt_boxes_val)) * 100\n",
    "error_train = ((get_items(gt_boxes_train) - results_train['tp']) / get_items(gt_boxes_train)) * 100\n",
    "\n",
    "print('Error Val: ', error_val)\n",
    "print('Error Train: ', error_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With cls_tresh = 0.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    results_filepath = '/scratch/ganswindt/retinanet/'\n",
    "    val = os.path.join(results_filepath, 'result_1306-2.json')\n",
    "    train = os.path.join(results_filepath, 'result_1306_train-2.json')\n",
    "\n",
    "    with open(val) as json_file:\n",
    "        dataset_val = json.load(json_file)\n",
    "\n",
    "    pred_data_val = get_matings(dataset_val)\n",
    "\n",
    "    with open(train) as json_file:\n",
    "        dataset_train = json.load(json_file)\n",
    "\n",
    "    pred_data_train = get_matings(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    results_val = dict()\n",
    "\n",
    "    results_val['tp'] = 0\n",
    "    results_val['fp'] = 0\n",
    "    results_val['fn'] = 0\n",
    "\n",
    "    counter = 0\n",
    "    counter_pred = 0\n",
    "\n",
    "    for d in pred_data_val:\n",
    "        for g in gt_boxes_val:\n",
    "\n",
    "            if d is g:\n",
    "\n",
    "                boxes = pred_data_val[d]\n",
    "                gt = gt_boxes_val[g]\n",
    "\n",
    "                counter += len(gt)\n",
    "                counter_pred += len(boxes)\n",
    "\n",
    "                tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "\n",
    "                results_val['tp'] = results_val['tp'] + tmp['tp']\n",
    "                results_val['fp'] = results_val['fp'] + tmp['fp']\n",
    "                results_val['fn'] = results_val['fn'] + tmp['fn']\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    print('Num Ground-Truth Boxes in Val: ', counter)\n",
    "    print('Num predicted Boxes for Val: ', counter_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    print('Results: ', results_val)\n",
    "\n",
    "    print((results_val['tp']/(results_val['tp'] + results_val['fp'])) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    results_train = dict()\n",
    "\n",
    "    results_train['tp'] = 0\n",
    "    results_train['fp'] = 0\n",
    "    results_train['fn'] = 0\n",
    "\n",
    "    counter = 0\n",
    "    counter_pred = 0\n",
    "\n",
    "    for d in pred_data_train:\n",
    "        for g in gt_boxes_train:\n",
    "\n",
    "            if d is g:\n",
    "\n",
    "                boxes = pred_data_train[d]\n",
    "                gt = gt_boxes_train[g]\n",
    "\n",
    "                counter += len(gt)\n",
    "                counter_pred += len(boxes)\n",
    "\n",
    "                tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "\n",
    "                results_train['tp'] = results_train['tp'] + tmp['tp']\n",
    "                results_train['fp'] = results_train['fp'] + tmp['fp']\n",
    "                results_train['fn'] = results_train['fn'] + tmp['fn']\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    print('Num Ground-Truth Boxes in Train: ', counter)\n",
    "    print('Num predicted Boxes for Val: ', counter_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 0:\n",
    "    print('Results: ', results_train)\n",
    "\n",
    "    print(results_train['tp']/counter_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with Mating Events splitted in 'good' and 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR_2 = '/scratch/ganswindt/retinanet/COCO_2_mating/DIR/'\n",
    "ANNOTATION_DIR_2 = os.path.join(ROOT_DIR_2, \"annotations\")\n",
    "\n",
    "results_filepath_2 = '/scratch/ganswindt/retinanet/'\n",
    "val_2 = os.path.join(results_filepath_2, 'result_2606-val-2.json')\n",
    "train_2 = os.path.join(results_filepath_2, 'result_2606-train-2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  done\n",
      "63  done\n"
     ]
    }
   ],
   "source": [
    "with open(val_2) as json_file:\n",
    "    dataset_val_2 = json.load(json_file)\n",
    "\n",
    "pred_data_val_2 = get_matings(dataset_val_2)\n",
    "\n",
    "with open(train_2) as json_file:\n",
    "    dataset_train_2 = json.load(json_file)\n",
    "\n",
    "pred_data_train_2 = get_matings(dataset_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "6\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "val_file_2 = ANNOTATION_DIR_2 + '/instances_val.json'\n",
    "train_file_2 = ANNOTATION_DIR_2 + '/instances_train.json'\n",
    "    \n",
    "gt_boxes_val_2 = read_json(val_file_2)\n",
    "gt_boxes_train_2 = read_json(train_file_2)\n",
    "\n",
    "#print(gt_boxes_val[70])\n",
    "print(len(gt_boxes_val_2))\n",
    "print(len(gt_boxes_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Ground-Truth Boxes in Train:  136\n",
      "Num predicted Boxes for Train:  159\n"
     ]
    }
   ],
   "source": [
    "results_train_2 = dict()\n",
    "\n",
    "results_train_2['tp'] = 0\n",
    "results_train_2['fp'] = 0\n",
    "results_train_2['fn'] = 0\n",
    "\n",
    "counter = 0\n",
    "counter_pred = 0\n",
    "\n",
    "for d in pred_data_train_2:\n",
    "    for g in gt_boxes_train_2:\n",
    "        \n",
    "        if d is g:\n",
    "               \n",
    "            boxes = pred_data_train_2[d]\n",
    "            gt = gt_boxes_train_2[g]\n",
    "            \n",
    "            counter += len(gt)\n",
    "            counter_pred += len(boxes)\n",
    "            \n",
    "            tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "            \n",
    "            results_train_2['tp'] = results_train_2['tp'] + tmp['tp']\n",
    "            results_train_2['fp'] = results_train_2['fp'] + tmp['fp']\n",
    "            results_train_2['fn'] = results_train_2['fn'] + tmp['fn']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print('Num Ground-Truth Boxes in Train: ', counter)\n",
    "print('Num predicted Boxes for Train: ', counter_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'tp': 141, 'fp': 18, 'fn': 8}\n",
      "88.67924528301887 %\n"
     ]
    }
   ],
   "source": [
    "print('Results:', results_train_2)\n",
    "\n",
    "#1306: 85.26 %\n",
    "print(results_train_2['tp']/(results_train_2['tp'] + results_train_2['fp']) * 100, '%')\n",
    "# for Pred data with 3 classes: 39.93808049535604 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Ground-Truth Boxes in Val:  9\n",
      "Num predicted Boxes for Val:  14\n"
     ]
    }
   ],
   "source": [
    "results_val_2 = dict()\n",
    "\n",
    "results_val_2['tp'] = 0\n",
    "results_val_2['fp'] = 0\n",
    "results_val_2['fn'] = 0\n",
    "\n",
    "counter = 0\n",
    "counter_pred = 0\n",
    "\n",
    "for d in pred_data_val_2:\n",
    "    for g in gt_boxes_val_2:\n",
    "        \n",
    "        if d is g:\n",
    "               \n",
    "            boxes = pred_data_val_2[d]\n",
    "            gt = gt_boxes_val_2[g]\n",
    "            \n",
    "            counter += len(gt)\n",
    "            counter_pred += len(boxes)\n",
    "            \n",
    "            tmp = intersects_with_gt(boxes, gt, 0.5, d)\n",
    "            \n",
    "            results_val_2['tp'] = results_val_2['tp'] + tmp['tp']\n",
    "            results_val_2['fp'] = results_val_2['fp'] + tmp['fp']\n",
    "            results_val_2['fn'] = results_val_2['fn'] + tmp['fn']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print('Num Ground-Truth Boxes in Val: ', counter)\n",
    "print('Num predicted Boxes for Val: ', counter_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'tp': 8, 'fp': 6, 'fn': 2}\n",
      "57.14285714285714 %\n"
     ]
    }
   ],
   "source": [
    "print('Results: ', results_val_2)\n",
    "\n",
    "#1306: 19.49 %\n",
    "print(results_val_2['tp']/(results_val_2['tp'] + results_val_2['fp']) * 100, '%')\n",
    "\n",
    "# for pred data with three classes: 34.61538461538461 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate True Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_no_matings(pred_dataset):\n",
    "\n",
    "    pred_data = dict()\n",
    "\n",
    "    for d in pred_dataset:\n",
    "    \n",
    "        idx = d['image_id']\n",
    "        bbox = [float(x) for x in d['bbox']]\n",
    "        \n",
    "        if d['category_id'] is not 1:\n",
    "    \n",
    "            if idx in pred_data:\n",
    "        \n",
    "                pred_data[idx].append(bbox)        \n",
    "            else:\n",
    "        \n",
    "                tmp = []\n",
    "        \n",
    "                tmp.append(bbox)\n",
    "        \n",
    "                pred_data[idx] = tmp\n",
    "\n",
    "    print(len(pred_data), ' done')\n",
    "    \n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_json(filepath):\n",
    "    \n",
    "    result_data = dict()\n",
    "    \n",
    "    with open(filepath) as json_file:\n",
    "        train_dataset = json.load(json_file)\n",
    "        \n",
    "    ann = train_dataset['annotations']\n",
    "    #print(ann)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for a in ann:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        if a['category_id'] is not 1:\n",
    "            \n",
    "            #print(a)\n",
    "            \n",
    "            idx = a['image_id']\n",
    "            tmp_box = [float(x) for x in a['bbox']]\n",
    "            \n",
    "            x2 = tmp_box[0] + tmp_box[2]\n",
    "            y2 = tmp_box[1] + tmp_box[3]\n",
    "            \n",
    "            bbox = [tmp_box[0], tmp_box[1], x2, y2]\n",
    "        \n",
    "            if idx in result_data:\n",
    "            \n",
    "                result_data[idx].append(bbox)\n",
    "            else:\n",
    "                \n",
    "                tmp = []\n",
    "                tmp.append(bbox)\n",
    "                result_data[idx] = tmp\n",
    "    \n",
    "    #print('Iterated through: ', counter, \" images.\")\n",
    "    print('done')\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(li):\n",
    "    \n",
    "    count = 0\n",
    "    for x in li:\n",
    "        if isinstance(li[x], list): \n",
    "            count += len(li[x])\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  done\n",
      "69  done\n"
     ]
    }
   ],
   "source": [
    "pred_no_val = get_all_no_matings(dataset_val)\n",
    "\n",
    "pred_no_train = get_all_no_matings(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "8\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "gt_all_val = read_all_json(val_file)\n",
    "gt_all_train = read_all_json(train_file)\n",
    "\n",
    "#print(gt_boxes_val[70])\n",
    "print(len(gt_all_val))\n",
    "print(len(gt_all_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_val = get_items(gt_all_val) - get_items(pred_no_val)\n",
    "tn_train = get_items(gt_all_train) - get_items(pred_no_train)\n",
    "\n",
    "results_val['tn'] = tn_val\n",
    "results_train['tn'] = tn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:  {'tp': 30, 'fp': 8, 'fn': 34, 'tn': 285}\n",
      "Train:  {'tp': 357, 'fp': 15, 'fn': 272, 'tn': 2104}\n"
     ]
    }
   ],
   "source": [
    "print('Val: ', results_val)\n",
    "print('Train: ', results_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For dataset with 4 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  done\n",
      "72  done\n"
     ]
    }
   ],
   "source": [
    "pred_no_val_2 = get_all_no_matings(dataset_val_2)\n",
    "\n",
    "pred_no_train_2 = get_all_no_matings(dataset_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "8\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "gt_all_val_2 = read_all_json(val_file)\n",
    "gt_all_train_2 = read_all_json(train_file)\n",
    "\n",
    "#print(gt_boxes_val[70])\n",
    "print(len(gt_all_val_2))\n",
    "print(len(gt_all_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_val_2 = get_items(gt_all_val_2) - get_items(pred_no_val_2)\n",
    "tn_train_2 = get_items(gt_all_train_2) - get_items(pred_no_train_2)\n",
    "\n",
    "results_val_2['tn'] = tn_val_2\n",
    "results_train_2['tn'] = tn_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:  {'tp': 10, 'fp': 9, 'fn': 2}\n",
      "Train:  {'tp': 187, 'fp': 19, 'fn': 5}\n"
     ]
    }
   ],
   "source": [
    "print('Val: ', results_val_2)\n",
    "print('Train: ', results_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT:  9\n",
      "Prediction:  8\n",
      "Error Val:  11.11111111111111\n",
      "Error Train:  -3.6764705882352944\n"
     ]
    }
   ],
   "source": [
    "error_val_2 = ((get_items(gt_boxes_val_2) - results_val_2['tp']) / get_items(gt_boxes_val_2)) * 100\n",
    "error_train_2 = ((get_items(gt_boxes_train_2) - results_train_2['tp']) / get_items(gt_boxes_train_2)) * 100\n",
    "\n",
    "print('GT: ', get_items(gt_boxes_val_2))\n",
    "print('Prediction: ', results_val_2['tp'])\n",
    "print('Error Val: ', error_val_2)\n",
    "print('Error Train: ', error_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-84ba535b9f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSens_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mSpec_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mPrec_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mTPR_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tn'"
     ]
    }
   ],
   "source": [
    "error_val = ((get_items(gt_boxes_val) - results_val['tp']) / get_items(gt_boxes_val)) * 100\n",
    "error_train = ((get_items(gt_boxes_train) - results_train['tp']) / get_items(gt_boxes_train)) * 100\n",
    "\n",
    "Sens_val = results_val['tp'] / results_val['tp'] + results_val['fn']\n",
    "Spec_val = results_val['tn'] / results_val['tn'] + results_val['fp']\n",
    "Prec_val = results_val['tp'] / results_val['tp'] + results_val['fp']\n",
    "TPR_val = results_val['tp'] / results_val['tp'] + results_val['fn']\n",
    "FPR_val = results_val['fp'] / results_val['fp'] + results_val['tn']\n",
    "TNR_val = results_val['tn'] / results_val['tn'] + results_val['fp']\n",
    "FNR_val = results_val['fn'] / results_val['fn'] + results_val['tp']\n",
    "\n",
    "Sens_train = results_train['tp'] / results_train['tp'] + results_train['fn']\n",
    "Spec_train = results_train['tn'] / results_train['tn'] + results_train['fp']\n",
    "Prec_train = results_train['tp'] / results_train['tp'] + results_train['fp']\n",
    "TPR_train = results_train['tp'] / results_train['tp'] + results_train['fn']\n",
    "FPR_train = results_train['fp'] / results_train['fp'] + results_train['tn']\n",
    "TNR_train = results_train['tn'] / results_train['tn'] + results_train['fp']\n",
    "FNR_train = results_train['fn'] / results_train['fn'] + results_train['tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Val:  43.75\n",
      "Error Train:  31.319554848966614\n",
      "Sens Val:  29.0\n",
      "Spec Val:  9.0\n",
      "Prec Val:  9.0\n",
      "TPR Val:  35.0\n",
      "FPR Val:  286.0\n",
      "TNR Val:  9.0\n",
      "FNR Val:  31.0\n",
      "Sens Train:  273.0\n",
      "Spec Train:  16.0\n",
      "Prec Train:  16.0\n",
      "TPR Train:  273.0\n",
      "FPR Train:  2105.0\n",
      "TNR Train:  16.0\n",
      "FNR Train:  358.0\n"
     ]
    }
   ],
   "source": [
    "print('Error Val: ', error_val)\n",
    "print('Error Train: ', error_train)\n",
    "\n",
    "print('Sens Val: ', Sens_val)\n",
    "print('Spec Val: ', Spec_val)\n",
    "print('Prec Val: ', Prec_val)\n",
    "print('TPR Val: ', TPR_val)\n",
    "print('FPR Val: ', FPR_val)\n",
    "print('TNR Val: ', TNR_val)\n",
    "print('FNR Val: ', FNR_val)\n",
    "\n",
    "print('Sens Train: ', Sens_train)\n",
    "print('Spec Train: ', Spec_train)\n",
    "print('Prec Train: ', Prec_train)\n",
    "print('TPR Train: ', TPR_train)\n",
    "print('FPR Train: ', FPR_train)\n",
    "print('TNR Train: ', TNR_train)\n",
    "print('FNR Train: ', FNR_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
